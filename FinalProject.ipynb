{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "def progress(count, total, suffix=''):\n",
    "    bar_len = 60\n",
    "    filled_len = int(round(bar_len * count / float(total)))\n",
    "\n",
    "    percents = round(100.0 * count / float(total), 1)\n",
    "    bar = '=' * filled_len + '-' * (bar_len - filled_len)\n",
    "\n",
    "    sys.stdout.write('[%s] %s%s ...%s\\r' % (bar, percents, '%', suffix))\n",
    "    sys.stdout.flush()  # As suggested by Rom Ruben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn import preprocessing as sklpp\n",
    "from sklearn import decomposition as skldecomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting file images/data_batch_1...\n",
      "Finished Extracting Features\n",
      "(10000, 3072)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Extracting data into a file\n",
    "\"\"\"\n",
    "data = None\n",
    "labels = []\n",
    "\n",
    "file = \"images/data_batch_1\"\n",
    "with open(file, 'rb') as fo:\n",
    "    print(\"extracting file \"+file+\"...\")\n",
    "    dict = pickle.load(fo, encoding='bytes')\n",
    "    temp_data = dict[b'data']\n",
    "    try:\n",
    "        data = np.concatenate((data, temp_data), axis=0)\n",
    "    except:\n",
    "        data = temp_data\n",
    "    labels = labels + dict[b'labels']\n",
    "labels = np.array(labels)\n",
    "labels = labels.reshape(-1,1)\n",
    "print(\"Finished Extracting Features\")\n",
    "print(np.shape(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and Feature Learning For Images Dataset\n",
    "For preprocessing we centered our dataset to 0 mean and then for feature learning we apply PCA to reduce our dimensions from 3072 to a smaller number of features than contains 95% of the variance of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we create a StandardScaler object to 0 mean the data matrix but preserve the variance\n",
    "stand_scaler = sklpp.StandardScaler(with_mean = True, with_std = False)\n",
    "# Fits the data matrix to the StandardScaler object defined ^\n",
    "centered_ImageData = stand_scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a PCA object that reduces the dimensions of our data matrix keeping 95% of the variance\n",
    "pca_obj = skldecomp.PCA(n_components = 0.95, svd_solver = 'auto')\n",
    "dim_reducedImageData = pca_obj.fit_transform(centered_ImageData)\n",
    "np.save('dim_reducedImageData.npy', dim_reducedImageData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been reduced to 209 features after PCA\n"
     ]
    }
   ],
   "source": [
    "print('Data has been reduced to {} features after PCA'.format(dim_reducedImageData.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "[============================================================] 100.0% ...training k= 1\n",
      "0.102========================================================] 100.0% ...testing k= 1\n",
      "1000\n",
      "[============================================================] 100.0% ...training k= 2\n",
      "[=-----------------------------------------------------------] 1.0% ...testing k= 2\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-85edbb09e49b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mprogress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"testing k= \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mtesting_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mestimateBestLabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m             \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-85edbb09e49b>\u001b[0m in \u001b[0;36mestimateBestLabel\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0msecond_term\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minverted_variance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mthird_term\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minverted_variance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0mfourth_term\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigmas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0mfifth_term\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst_term\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msecond_term\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mthird_term\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfourth_term\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfifth_term\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projects/ml_engineering/anaconda3/lib/python3.7/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36mdet\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m   2091\u001b[0m     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_commonType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2092\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->D'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->d'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2093\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_umath_linalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2094\u001b[0m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2095\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Pull pca data from saved\n",
    "\"\"\"\n",
    "data = np.load('dim_reducedImageData.npy')\n",
    "data = np.concatenate((data,labels),axis=1)\n",
    "number_of_parameters = len(data[0]) - 1 #209\n",
    "number_of_total_samples = len(data)\n",
    "\"\"\"\n",
    "K-Fold cross validation \n",
    "\"\"\"     \n",
    "final_estimates = []\n",
    "k = 10\n",
    "for i in range(1,k+1):\n",
    "    training_data = np.concatenate((data[0:(i-1)*int(number_of_total_samples/k)],data[i*int(number_of_total_samples/k):number_of_total_samples]),axis=0)\n",
    "    testing_data = data[(i-1)*int(number_of_total_samples/k):i*int(number_of_total_samples/k)]\n",
    "    number_of_training_samples = len(training_data)\n",
    "    print(len(testing_data))\n",
    "    \"\"\"\n",
    "    Define Parameters \n",
    "    \"\"\"\n",
    "    mu = [[0 for j in range(number_of_parameters)] for i in range(10)] # initializing means \n",
    "    sigmas = [[[0 for k in range(number_of_parameters)] for j in range(number_of_parameters)] for i in range(10)] # initializing variances\n",
    "    occurences = [0 for i in range(10)]\n",
    "    pi = [0 for i in range(10)]\n",
    "        \n",
    "    \"\"\"\n",
    "    Learn mu\n",
    "    \"\"\"\n",
    "    # Find Sums and Occurences\n",
    "    for image in training_data:\n",
    "        label = int(image[-1])\n",
    "        occurences[label] += 1\n",
    "        mu[label] = np.add(mu[label],image[:-1])\n",
    "    # Calculate Averages and Prior Probabilities \n",
    "    for label,sums in enumerate(mu):\n",
    "        mu[label] = np.multiply(1/(occurences[label] - 1), sums).reshape(-1,1) #unbaised estimator\n",
    "        pi[label] = occurences[label] / number_of_total_samples\n",
    "    \"\"\"\n",
    "    Learn sigma^2\n",
    "    \"\"\"\n",
    "    time = 0\n",
    "    for image in training_data:\n",
    "        time += 1\n",
    "        if time%10 == 0:\n",
    "            progress(time,number_of_training_samples,suffix=\"training k= \"+str(i))\n",
    "        label = int(image[-1])\n",
    "        image = image[:-1].reshape(-1,1)\n",
    "        difference = np.subtract(image,mu[label])\n",
    "        sigma = difference.dot(difference.T)\n",
    "        sigmas[label] = np.add(sigmas[label],sigma)\n",
    "    for label,sigma in enumerate(sigmas):\n",
    "        sigmas[label] = np.multiply(1/(occurences[label]-1),sigma)\n",
    "    sys.stdout.flush()\n",
    "    \"\"\"\n",
    "    Method to find the best discriminant score\n",
    "    \"\"\"\n",
    "    def estimateBestLabel(image):\n",
    "        scores = [0 for _ in range(10)]\n",
    "        # find score for each label \n",
    "\n",
    "        for label in range(10):\n",
    "            inverted_variance = np.linalg.inv(sigmas[label])\n",
    "            first_term = -0.5*image.T.dot(inverted_variance).dot(image)\n",
    "            second_term = image.T.dot(inverted_variance).dot(mu[label])\n",
    "            third_term = -0.5*mu[label].T.dot(inverted_variance).dot(mu[label])\n",
    "            fourth_term = -0.5*math.log(np.linalg.det(sigmas[label]))\n",
    "            fifth_term = math.log(pi[label])\n",
    "            score = first_term + second_term + third_term + fourth_term + fifth_term\n",
    "            scores[label] = score[0][0]\n",
    "        return(scores.index(max(scores)))\n",
    "    correct = 0\n",
    "    print(\"\")\n",
    "    for index, image in enumerate(testing_data):\n",
    "        if index % 9 == 0:\n",
    "            progress(index+1,1000,suffix=\"testing k= \"+str(i))\n",
    "        image = image[:-1].reshape(-1,1)\n",
    "        if testing_data[index][-1] == estimateBestLabel(image):\n",
    "            correct += 1\n",
    "    sys.stdout.flush()\n",
    "    print(correct/1000)\n",
    "    final_estimates.append(correct/1000)\n",
    "print(\"\")\n",
    "print(final_estimates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 209)\n",
      "[[-1.66786333e+03 -7.04951956e+02  3.55547396e+02 ...  7.55617243e+00\n",
      "  -1.14070900e+00  4.09839209e+00]\n",
      " [ 1.68718819e+02  2.14158957e+02  1.55982239e+03 ... -4.81034742e-01\n",
      "   1.70525575e+02 -9.91542640e+01]\n",
      " [ 1.96093846e+03  2.93034428e+03 -6.31292284e+02 ...  1.08215500e+02\n",
      "  -4.71960005e+00  9.61573393e+00]\n",
      " ...\n",
      " [-3.30327785e+02  2.43792701e+03 -3.74213598e+02 ...  3.09124236e+01\n",
      "   8.47475854e+01  6.67568700e+01]\n",
      " [ 1.79608664e+02 -4.50775000e+02 -4.10255349e+02 ... -4.43966999e+01\n",
      "   1.06159623e+01  9.79147309e+01]\n",
      " [-6.32447973e+02 -1.60751972e+03  4.78398657e+02 ...  1.08987396e+01\n",
      "   1.66306361e+00  6.50439553e+01]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1)\n",
      "[[6]\n",
      " [9]\n",
      " [9]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [5]]\n"
     ]
    }
   ],
   "source": [
    "labels = np.array(labels)\n",
    "labels = labels.reshape(-1,1)\n",
    "print(np.shape(labels))\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
