{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing as sklpp\n",
    "from sklearn import decomposition as skldecomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting file images/data_batch_1...\n",
      "Finished Extracting Features\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Extracting data into a file\n",
    "Keeping only 10,000 samples of the 50,000\n",
    "\n",
    "\"\"\"\n",
    "data = None\n",
    "labels = []\n",
    "\n",
    "file = \"images/data_batch_1\"\n",
    "with open(file, 'rb') as fo:\n",
    "    print(\"extracting file \"+file+\"...\")\n",
    "    dict = pickle.load(fo, encoding='bytes')\n",
    "    temp_data = dict[b'data']\n",
    "    try:\n",
    "        data = np.concatenate((data, temp_data), axis=0)\n",
    "    except:\n",
    "        data = temp_data\n",
    "    labels = labels + dict[b'labels']\n",
    "\n",
    "print(\"Finished Extracting Features\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing and Feature Learning image dataset\n",
    "Each sample in our data matrix for the images has 3072 raw features therefore we will perform dimensionality reduction of the data via PCA in order to ease our computation time. We will do PCA with 95% of the variance preserved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First step to PCA is to center our data matrix to ensure it has 0 mean we use SciKit-Learn for this step\n",
    "# Creates an instance of a StandardScaler() object that centers the data matrix to  0 mean but does not change variance \n",
    "mean_datascaler = sklpp.StandardScaler(with_mean = True, with_std = False)\n",
    "# Using the fit_transform method we get our centered data\n",
    "centered_ImageData = mean_datascaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Next we use SciKit-Learn PCA method to perform linear dimensionality reduction via PCA preserving 95% of the variance\n",
    "# Here we create a PCA object and pass in n_components = 0.95 so that 95% of the variance is contained in the reduced dimensions\n",
    "pca_object = skldecomp.PCA(n_components = 0.95,svd_solver = 'auto')\n",
    "# transforms the centered_ImageData to the reduced dimension in a new variable, this does all the SVD and preserves only the top principle components that will result in 95% energy capture\n",
    "# based on the singular values.\n",
    "dim_reducedImageData = pca_object.fit_transform(centered_ImageData)\n",
    "np.save('dim_reducedImageData.npy',dim_reducedImageData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
